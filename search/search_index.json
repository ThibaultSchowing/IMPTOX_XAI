{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>These pages aim to guide IMPTOX members in creating and interpreting models for tabular numerical data. The shown sample workflows assume fully numeric datasets, including ordinal categories or one-hot encodings, and focuses on predicting a target variable (classification or regression). To illustrate these methods, we will apply XAI techniques to well-known example datasets such as the Pima Indians Diabetes Database and the Heart Disease Dataset.</p>"},{"location":"#the-project","title":"The project","text":"<p>IMPTOX Project</p> <p>Microplastics and nanoplastics (MNP) are a growing concern for human health and the environment. The IMPTOX project brings together scientists from diverse fields\u2014chemistry, biology, and medicine to investigate this pressing issue. Whether you're measuring MNP in environmental or animal samples, studying their impact on biofilms, tracking them as pathogen carriers, or exploring medical effects such as allergies, the project generates a wealth of complex and valuable data.</p> <p>Data is only the beginning. How do we extract meaningful insights or create prediction models from high dimentional and complex data? This is where machine learning (ML) and Explainable Artificial Intelligence (XAI) come into play. XAI helps transform data into knowledge by offering transparent and interpretable models that reveal the why behind predictions.</p>"},{"location":"#what-is-machine-learning-and-how-can-it-help","title":"What is machine learning and how can it help?","text":"Why machine learning? <p>While traditional statistical analysis excels at accurately describing data and identifying patterns, machine learning algorithms offer the ability to explore more complex and high-dimensional datasets. These advanced methods can capture intricate relationships and non-linear interactions that classic techniques might overlook.  Moreover, machine learning models have the potential to deliver more accurate predictions by learning from complex data interactions. </p> How machine learning could help with your research? <p>Machine learning allows you to go beyond observations, transforming data into predictions and new hypotheses. With XAI methods, these predictions become understandable and scientifically valuable, allowing to eliminate unused variables and focus on important ones, opening doors to optimized research paths. </p> <ul> <li>Environmental Insights: Could patterns in environmental data reveal which microplastic types are present or how they are distributed across ecosystems? </li> <li>Pathogen Risks: Can we uncover hidden relationships between microplastic chemical properties and their role in fostering pathogen growth? </li> <li>Health Predictions: Is it possible to predict health outcomes, such as allergic responses, based on exposure to microplastics combined with patient genotype ? </li> </ul> The different types of XAI <p>TODO - ABE</p> <p>Highlighting</p>"},{"location":"#expected-explainable-results","title":"Expected explainable results","text":"<p>Here is an extract of the type of result you can get with the methods explored here.</p> Random ForestSHAPDIMLP FidexFuzzy CoCo <p>Global rules overview <pre><code>Number of rules : \n    -152, \n    -mean sample covering number per rule : 11.572368, \n    -mean number of antecedents per rule : 3.085526\nNo decision threshold is used.\n\nRule 1: Glucose&lt;104.5 BMI&lt;28.8 -&gt; class 0\nTrain Covering size : 81\nTrain Fidelity : 1\nTrain Accuracy : 1\nTrain Confidence : 0.980741\n</code></pre></p> <p></p> <p></p> <p>The created model:</p> <ul> <li>IF (Glucose is Glucose.3), THEN (OUT is OUT.2)</li> <li>IF (Age is Age.1), THEN (OUT is OUT.1)] </li> <li>ELSE (OUT is OUT.2)</li> </ul> <p>Here a test sample is fuzzified and we can see the different rules activations: </p> <p></p>"},{"location":"aInstallation/","title":"Getting Started","text":"<p>If you do not plan to run these notebooks locally, you can view and execute them on Google Colab: </p> <p>Google Colab</p> <p>The notebooks should be available on Colab soon.  </p> <ol> <li>Random Forest and Fidex</li> <li>DIMPL-Fidex</li> <li>SHAP</li> <li>FuzzyCoCo</li> </ol>"},{"location":"aInstallation/#environments-setup","title":"Environments setup","text":"<p>For Windows user, we advise to use the Windows Subsystem for Linux (WSL) which allows, among many things, to run Python and compile packages in a Linux environment while accessing your notebooks from Windows. </p> <p>To try these examples, clone this GitHub repository or copy the desired files on your local machine and follow the instructions bellow. </p>"},{"location":"aInstallation/#create-virtual-environments","title":"Create virtual environments","text":"<p>Some methods require specific packages and thus, we will use a different virtual environment for each example. Here we create the following: </p> <ol> <li> <p><code>.venvrf</code> for Random Forest</p> </li> <li> <p><code>.venvshap</code> to use Gradient SHAP over a simple Neural Network</p> </li> <li> <p><code>.venvrf</code> can be used again for DIMLP Fidex</p> </li> <li> <p><code>.venvfuzzycoco</code> for FUGE. The package is not yet publicly available and needs to be compiled locally. </p> </li> </ol> From scratchFrom txt files <pre><code># 1 - Start WSL and\n# 2 - Create the virtual environments\n\npython -m venv .venvrf notebook numpy pandas matplotlib seaborn dimlpfidex kagglehub scikit-learn\npython -m venv .venvshap notebook numpy pandas matplotlib seaborn torch torchaudio torchvision kagglehub scikit-learn\n# - for fuzzy coco installation follow the next step bellow\n</code></pre> <pre><code># 1 - Start WSL and\n# 2 - Create the virtual environments from files\n\npython3 -m venv .venvNAME # Replace .venvNAME with the desired name\nsource .venvNAME/bin/activate\n\n# 3 - Within your virtual environment, install from the given txt file. \npython3 -m pip install -r requirements.txt\n</code></pre> <p>Once you have your environments created:</p> <pre><code># 3 - Activate the desired environment (replace .venv by the created directory)\n\nsource .venv/bin/activate\n\n# 4 - Start the Jupyter server on WSL. Specify a different port for each environment if you run them in parallel\n\njupyter notebook --no-browser --port 9898\n</code></pre>"},{"location":"aInstallation/#environment-for-fuzzy-coco","title":"Environment for Fuzzy CoCo","text":"<p>Currently FuzzCoCoPython is under developpment and will be soon available for Unix based systems (MacOS and Linux). </p> <ol> <li>Clone this repository (NOT PUBLIC YET). </li> </ol> <pre><code>python -m venv .venvfuzzycoco notebook numpy pandas matplotlib seaborn \nsource .venvfuzzycoco/bin/activate \n\n# from the fuzzycocopython repository folder\npython -m pip install .\n</code></pre>"},{"location":"bData/","title":"Example data","text":"<p>To present the different methods with simplicity, we will use a well known toy dataset</p>"},{"location":"bData/#context","title":"Context","text":"<p>Here we present a simple dataset from Kaggle with only numerical data for simplicity. This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient (woman only) has diabetes, based on certain diagnostic measurements included in the dataset.  </p>"},{"location":"bData/#content","title":"Content","text":"<p>The datasets consists of several medical predictor variables and one target variable (OUT). Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.</p> <p>However, there are various way to explain categorical data as well. For example, SHAP can be used to explain where on an image a Neural Network used for object detection focuses</p> Pregnancies Glucose BloodPressure SkinThickness Insulin BMI DiabetesPedigreeFunction Age OUT 0 1 85 66 29 0 26.6 0.351 31 0 1 8 183 64 0 0 23.3 0.672 32 1 2 1 89 66 23 94 28.1 0.167 21 0 3 0 137 40 35 168 43.1 2.288 33 1 4 5 116 74 0 0 25.6 0.201 30 0 5 3 78 50 32 88 31 0.248 26 1 6 10 115 0 0 0 35.3 0.134 29 0 7 2 197 70 45 543 30.5 0.158 53 1 <p>Using categories and other data types</p> <p>If your data contain categories, models like Random Forest can easilly include them. However, this is not the case for Neural Networks and Fuzzy Logic with FUGE. To circumvent this, you can either convert your cartegories to numbers, if it makes sense or use one-hot encoding. For Neural Networks for object detection in images, SHAP can be applied to show the region of the image leading to the decision. You can find more details on the HES-XPLAIN plateform. </p>"},{"location":"bRandom-Forest/","title":"Random Forest","text":"<p>Simple but powerful, Random Forest creates an ensemble of decision trees which each contain already interpretable but numerous rules. Using a modified version with the Fidex algorithm allows to extract clear decision rules making the model more transparent and human readable.  </p> <p>The model obtains a 69% test accuracy and the rules, local (per sample) and global(over all) leading to this classification result are the following. </p> Local rulesGlobal rules <p><pre><code>Rule for sample 0 :\n\nGlucose&gt;=158.5 Glucose&lt;160.5 -&gt; class 1\nTrain Covering size : 2\nTrain Fidelity : 1\nTrain Accuracy : 1\nTrain Confidence : 0.823333\n\n-------------------------------------------------\n\nRule for sample 1 :\n\nGlucose&lt;89.5 BloodPressure&gt;=82.5 -&gt; class 0\nTrain Covering size : 4\nTrain Fidelity : 1\nTrain Accuracy : 1\nTrain Confidence : 0.904\n</code></pre> The local rules are the rules attributed to each test sample individually.</p> <p><pre><code>Number of rules : 152, mean sample covering number per rule : 11.572368, mean number of antecedents per rule : 3.085526\nNo decision threshold is used.\n\nRule 1: Glucose&lt;104.5 BMI&lt;28.8 -&gt; class 0\nTrain Covering size : 81\nTrain Fidelity : 1\nTrain Accuracy : 1\nTrain Confidence : 0.980741\n\nRule 2: Glucose&lt;106.5 Age&lt;25.5 BMI&lt;34.900002 -&gt; class 0\nTrain Covering size : 79\nTrain Fidelity : 1\nTrain Accuracy : 1\nTrain Confidence : 0.982278\n</code></pre> The global rules represent the whole test samples and are ordered by coverage i.e. the number of sample they are applied to. </p> <p>You can find the notebook in the GitHub repository by clicking the link in the top-right corner. </p>"},{"location":"cMLP/","title":"Gradient SHAP","text":"<p>SHAP (SHapley Additive exPlanations) is a model-agnostic interpretability method based on cooperative game theory. </p> <p>How does SHAP work ?</p> <p>It assigns each feature in a model an importance value, which represents its contribution to a particular prediction. The method ensures fair and consistent allocation of importance scores by leveraging the properties of Shapley values, a well-established solution concept from cooperative game theory. One of SHAP's key advantages is its ability to explain complex, non-linear models by decomposing their predictions into additive contributions from individual features.</p> <p>In this example, we use a simple Multi-Layer Perceptron (MLP) model to demonstrate SHAP's utility. However, SHAP and its variants, such as Gradient SHAP, are compatible with any type of machine learning model, including tree-based models, support vector machines, and neural networks of any architecture. GradientShap approximates SHAP values by computing the expectations of gradients by randomly sampling from the distribution of baselines/references, providing more stable explanations by leveraging multiple baseline distributions and backpropagation.</p> <p>Our example demonstrate the explainability provided by Gradient SHAP, allowing us to identify the features that most contribute to model predictions in various scenarios, such as true positives, false positives, false negatives, and true negatives. The visualizations offer valuable insights into the decision-making process of the MLP and emphasize the importance of transparent AI models in complex problem domains. </p>"},{"location":"cMLP/#model-architecture-and-results","title":"Model architecture and results","text":"ModelResults <p>Here we create a simple MLP with N_features input, one hidden layer of 64 neurons, and a single neuron output for the True/False result. </p> <pre><code>class BinaryClassification(nn.Module):\n    def __init__(self):\n        super(BinaryClassification, self).__init__()\n        # Number of input features is MLP_INPUT_SIZE.\n        self.layer_1 = nn.Linear(MLP_INPUT_SIZE, 64) \n        self.layer_2 = nn.Linear(64, 64)\n        self.layer_out = nn.Linear(64, 1) \n        self.relu = nn.ReLU()\n        self.batchnorm1 = nn.BatchNorm1d(64)\n        self.batchnorm2 = nn.BatchNorm1d(64)\n        self.dropout = nn.Dropout(p=0.5)  # Randomly zero out neurons to avoid overfitting\n\n\n    def forward(self, inputs):\n        x = self.relu(self.layer_1(inputs))\n        x = self.batchnorm1(x)\n        x = self.relu(self.layer_2(x))\n        x = self.batchnorm2(x)\n        x = self.dropout(x)\n        x = self.layer_out(x)\n\n        return x\n</code></pre> <p>The prediction results are shown in the confusion matrix bellow. Here we have a 71% test accuracy, as good as these results may be, we do not have any explanation on why these decisions were made, as neural networks are black box models. </p> <p></p>"},{"location":"cMLP/#model-training-results-and-explanations","title":"Model training, results and explanations","text":"<p>We applied Gradient SHAP to the testing data by generating feature attributions for each individual sample. For every sample, the input features are perturbed using baseline references, and the corresponding changes in the model's output are analyzed. This process captures the contribution of each feature to the prediction.</p> <p>To derive meaningful insights at the group level, we aggregated the feature attributions across all samples grouped by True Positives, True Negatives, False Positives and False Negatives. This allowed us to summarize the overall influence of each feature on the model's predictions. The resulting visualizations, as shown in the figures below, highlight the averaged feature contributions along with confidence intervals, providing a clear and interpretable representation of the model's decision-making patterns.</p> True PositivesTrue NegativesFalse PositivesFalse Negatives <p></p> <p></p> <p></p> <p></p>"},{"location":"cMLP/#global-explanations","title":"Global explanations","text":"<p>Here we can have an insight on which feature drives the result toward a positive or negative prediction within the different result groups. This tells us for instance that the Glucose level is a powerful feature for the True Positive and True Negatives groups but it also drives falso positive results toward a positive prediction. We could conclude that glucose alone is a powerful predictor but is unstable. We can average the SHAP values and look at the global variable influence to get a broader view on the variables influences.</p> <p></p> <p>You can find the notebook in the GitHub repository by clicking the link in the top-right corner. </p>"},{"location":"dDIMLP-Fidex/","title":"DIMLP Fidex","text":"<p>The DIMLP-Fidex framework is made from DIMLP, \u00e0 speclalized feed-forsward neural network architecture derived from the traditional MLP (Multi Layer Perceptron) and from the FIDEX algorithm itself focuses on extracting local rules to explain the predictions of a pre-trained model for given data samples. Each of the other algorithms builds upon this foundation to offer additional functionalities.</p>"},{"location":"dDIMLP-Fidex/#results-and-rules","title":"Results and rules","text":"<p>After the results are computed, the FIDEX algorithm computes local and global interpretable rules and displays them with the OmniXAI dashboard as shown bellow. </p> ResultsLocalGlobal <p> With the basic parameters, we obtain a 62% test accuracy.</p> <p></p> <p></p> <p>You can find the notebook in the GitHub repository by clicking the link in the top-right corner. </p>"},{"location":"eFuzzy-CoCo/","title":"Fuzzy Coco","text":"<p>Fuzzy CoCo is an algorithm that uses Fuzzy logic, a human readable way of creating variable and rules, and CoCo that stands for Coevolutionary Computation. You can find details in this paper or bellow is an as short as possible summary of how Fuzzy CoCo works.</p> Fuzzy Logic and Co-evolutionary computation <p>Fuzzy logic is an extension of classical logic that deals with reasoning in uncertain or imprecise environments. Unlike traditional binary logic, where variables must be strictly true (1) or false (0), fuzzy logic allows for degrees of truth between 0 and 1.  </p> <p>Work In Progress</p> <p>Over the past decade, FUGE, the software implementing Fuzzy CoCo, has undergone sporadic updates and been used by various users, resulting in multiple unmatched and gradually outdated versions. Recently, its GUI was removed, and the codebase was cleaned to facilitate integration into a Python package. The integration is still in progress, and the current version allows only model creation, prediction and a few beta visualization functions. Rule extraction, training process visualization, and additional features will be improved and available soon. Stay tuned!</p>"},{"location":"eFuzzy-CoCo/#fuzzy-variables","title":"Fuzzy Variables","text":"<p>Fuzzy variables represent real-world concepts that lack precise boundaries. For example, in a medical setting, \"Glucose level\" is not just \"present\" or \"absent\" a level of 60 mg/dl is normal, while 150 mg/dl is definitely high. Fuzzy variables can take on a range of values with different degrees of membership in categories like \"low,\" \"medium,\" and \"high.\"</p>"},{"location":"eFuzzy-CoCo/#membership-functions","title":"Membership Functions","text":"<p>A membership function defines how a fuzzy variable is mapped to a degree of belonging within a category. It assigns a value between 0 and 1 to indicate how strongly a given input belongs to a specific fuzzy set. For example, a temperature of 37.5\u00b0C might have a membership of 0.3 in the \"high fever\" category and 0.7 in the \"mild fever\" category. These functions can take different shapes, such as triangular, trapezoidal, or Gaussian, depending on the level of smoothness desired but our implementation only uses triangular functions for simplicity and efficience. </p>"},{"location":"eFuzzy-CoCo/#fuzzy-rules","title":"Fuzzy Rules","text":"<p>Fuzzy rules describe the relationships between fuzzy variables using \"if-then\" statements. These rules help make decisions based on imprecise input. With our model from the PIMA dataset we obtain the following:  </p> <p>Rules generated are human readable and matched with linguistic variables. This gives results as bellow with Variable.1, Variable.2 and Variable.3 corresponding to the number of sets selected (e.g. it could linguistically correspond to Small, Medium and Large).</p> <ul> <li>IF (Glucose is Glucose.3), THEN (OUT is OUT.2)</li> <li>IF (Age is Age.1), THEN (OUT is OUT.1)] </li> <li>ELSE (OUT is OUT.2)</li> </ul> <p>These rules allow for flexible, human-like reasoning, making fuzzy logic useful in decision support systems, medical diagnostics, and control systems.  </p>"},{"location":"eFuzzy-CoCo/#fuzzy-coco_1","title":"Fuzzy CoCo","text":"<p>To find the right values, e.g. where are the cutoffs for a variable to be small, medium or large, and to find the rules, FUGE uses Co-evolutionary Computation. Co-evolutionary computation is an extension of evolutionary algorithms (EAs) where multiple interacting populations evolve simultaneously. Instead of a single population optimizing in isolation, co-evolution involves different groups influencing each other's evolution, leading to more dynamic and adaptive solutions.</p>"},{"location":"eFuzzy-CoCo/#fuge","title":"FUGE","text":"<p>Currently, function are being implemented to visualize the training progress as well as the variable sets and resulting fuzzy model. For a test sample, the fuzzyfication looks like this:</p> <p> </p> <p>With the variable sets being: </p> Glucose Age Output <p>Once a name is given to the variable sets, the rules can be read like this:</p> <p>Translated version</p> <p>IF (Glucose is HIGH), THEN (OUT is MEDIUM)</p> <p>IF (Age is LOW), THEN (OUT is LOW)</p> <p>ELSE (OUT is MEDIUM)</p> <p>Which in a sentense would be: </p> <p>If the glucose level is high, then the probability of diabetes is medium. If the patient is young, the the probability of diabetes is low. Otherwise, the diabetes probability is medium. </p> <p>Depending on HOW low, medium or high the variables are activated, an average is calculated in the end to give how much probable diabetes is. </p>"}]}